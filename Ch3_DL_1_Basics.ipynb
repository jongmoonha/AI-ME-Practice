{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKrMEYPecVdY"
   },
   "source": [
    "# Chapter 3. Deep learning Practice\n",
    "##  \"Pytorch\" 라이브러리를 활용한 Basic Deep Neural Network 프로그래밍\n",
    "## 프로그래밍 구조\n",
    "0. 데이터 로드 및 전처리\n",
    "1. 모델정의\n",
    "2. 모델하이퍼 파라미터 설정\n",
    "3. 모델 학습\n",
    "4. 결과예측\n",
    "\n",
    "\n",
    "조건:\n",
    "- input 데이터: MNIST (0~9 숫자 이미지. -> [28x28] 크기 이미지를 [1x784] numeric data라고 생각한다.\n",
    "- objective: MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOAMr_VkffXl"
   },
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10716,
     "status": "ok",
     "timestamp": 1728980677692,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Xyas0IBMcINZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9055,
     "status": "ok",
     "timestamp": 1728980688075,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "eMCRu2JEgcNb",
    "outputId": "31a56809-a228-4353-cddc-7980a4686a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:04<00:00, 2.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 154kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.36MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0. 데이터 로드 & 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "'''\n",
    "ToTensor()의 기능\n",
    "이미지를 PIL 이미지 또는 numpy 배열의 구조를 \"Channel x Height x Width\"로 바꾸고,\n",
    "이미지 픽셀값 [0~225]를 [0~1]로 수정.\n",
    "'''\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1728980702347,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "x3cNEj8CyaKE"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1728978953925,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "4eBhWoN0hUGo"
   },
   "outputs": [],
   "source": [
    "# 1. 모델 정의\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 16)  # 첫 번째 레이어\n",
    "        self.fc2 = nn.Linear(16, 10)        # 세 번째 레이어 (출력층)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 입력 이미지를 1D 벡터로 변환\n",
    "        x = torch.relu(self.fc1(x)) # 첫 번째 레이어: ReLU\n",
    "        x = self.fc2(x) # 출력층: Softmax는 CrossEntropyLoss에 내장되어 있으므로 사용하지 않음\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1728979029920,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "H-h9fQygfbzc",
    "outputId": "4abf5322-d73e-49a2-f0f1-b518fa982f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 16]          12,560\n",
      "            Linear-2                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 12,730\n",
      "Trainable params: 12,730\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = SimpleNN().to(device)\n",
    "summary(model, (1, 28 * 28), device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1728979427732,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "-X22U1ewiswM"
   },
   "outputs": [],
   "source": [
    "# 2. 모델 하이퍼 파라미터 설정 - 손실 함수 및 옵티마이저 정의 (cross entropy, Adam 사용)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40241,
     "status": "ok",
     "timestamp": 1728979468581,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "B4uFEwybhWif",
    "outputId": "1930bab8-9dfd-44c3-89d3-7bf2ad119b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.16039104759693146\n",
      "Epoch 2, Loss: 0.1086849495768547\n",
      "Epoch 3, Loss: 0.207755446434021\n",
      "Epoch 4, Loss: 0.305350124835968\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. 모델 학습\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):  \u001b[38;5;66;03m# 5 epoch 학습\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 데이터를 device로 이동\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 옵티마이저 초기화\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    172\u001b[39m img = img.view(pic.size[\u001b[32m1\u001b[39m], pic.size[\u001b[32m0\u001b[39m], F_pil.get_image_num_channels(pic))\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.contiguous()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.ByteTensor):\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img.to(dtype=default_float_dtype).div(\u001b[32m255\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "for epoch in range(5):  # 5 epoch 학습\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device) # 데이터를 device로 이동\n",
    "        optimizer.zero_grad() # 옵티마이저 초기화\n",
    "        output = model(data) # 모델에 입력 데이터를 전달\n",
    "        loss = criterion(output, target) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 모델 파라미터(업데이트)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1728981030727,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "hWwVixVVgfSM"
   },
   "outputs": [],
   "source": [
    "# 4. 결과예측\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (Dropout이나 BatchNorm 비활성화)\n",
    "\n",
    "    test_loss_list = []\n",
    "    acc_list = []\n",
    "    with torch.no_grad():  # 테스트 시에는 기울기를 계산하지 않으므로 메모리 최적화\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)# 데이터를 모델과 동일한 디바이스로 이동\n",
    "            output = model(data)# 모델에 입력 데이터 전달\n",
    "            # 손실 계산\n",
    "            test_loss_list.append(criterion(output, target).item())\n",
    "            # 예측 결과와 실제 정답 비교\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 가장 높은 값의 인덱스를 예측으로 사용\n",
    "            acc_list.append(pred.eq(target.view_as(pred)).sum().item())\n",
    "    # 평균 손실 및 정확도 출력\n",
    "    test_loss = sum(test_loss_list) / len(test_loader.dataset)\n",
    "    accuracy = 100. * sum(acc_list)  / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "    return test_loss_list, acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7114,
     "status": "ok",
     "timestamp": 1728979613526,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Loo7Ve4O23w0",
    "outputId": "18f23b78-5212-48eb-fa14-fc4f09e2635d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1934, Accuracy: 94.56/10000 (94.56%)\n"
     ]
    }
   ],
   "source": [
    "test_loss_list, acc_list=test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDoqeqeb6etY"
   },
   "source": [
    "# Pytorch tuning list\n",
    "1. Activation layers\n",
    "  - torch.relu, torch.sigmoid, torch.tanh, torch.PReLU, 등 지원\n",
    "\n",
    "2. Optimizaer\n",
    "  - optim.Adam 외에도 (optim.Adadelta, optim.AdamW, optim.SGD, optim.RMSprop 등 지원함)  \n",
    "  (ex)\n",
    "  ```\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "  ```\n",
    "\n",
    "3. Mini-batch Training\n",
    "  - DataLoader에서 배치 크기를 조정\n",
    "\n",
    "4. Weight initialization\n",
    "  - torch.nn.init을 사용해서 초기화 사용자 함수(init_weights) 작성\n",
    "  - model.apply(init_weights)로 적용\n",
    "  - default: He Normal (from torch 2.1)\n",
    "  (ex)\n",
    "  ```\n",
    "  def init_weights(m):\n",
    "      if isinstance(m, nn.Linear):\n",
    "          nn.init.xavier_uniform_(m.weight)  # Xavier 초기화 적용\n",
    "          nn.init.constant_(m.bias, 0)       # 바이어스는 0으로 초기화\n",
    "  model = SimpleNN()\n",
    "  model.apply(init_weights)        \n",
    "  ```\n",
    "  \n",
    "5. Batch Normalization\n",
    "  - 각 레이어 사이에 nn.BatchNorm1d 입력해서 배치 정규화 추가\n",
    "  (ex)  \n",
    "  ```\n",
    "  self.bn2 = nn.BatchNorm1d(64)\n",
    "  ```\n",
    "\n",
    "6. Regularization\n",
    "  - L2 - reg: lambda = optimizer에서 weight_decay값 조절\n",
    "  - Dropout: nn.Dropout(비율) 로 조절(ex. nn.Dropout(0.5))\n",
    "\n",
    "### [튜닝 적용 예시]\n",
    "\n",
    "\n",
    "```\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 첫 번째 레이어 (28*28 input -> 128 hidden units)\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128) # Batch Normalization\n",
    "        self.dropout1 = nn.Dropout(0.5)  # 드롭아웃 추가 (50%)\n",
    "        \n",
    "        # 두 번째 레이어 (128 hidden units -> 64 hidden units)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64) # Batch Normalization\n",
    "        self.dropout2 = nn.Dropout(0.5)  # 드롭아웃 추가 (50%)\n",
    "        \n",
    "        # 세 번째 레이어 (64 hidden units -> 10 output units)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 레이어: ReLU활성화 + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # 두 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "model.apply(init_weights)  # 가중치 초기화 적용\n",
    "\n",
    "## 손실 함수 및 옵티마이저 정의 (Adam 사용, L2 정규화 적용)\n",
    "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss는 Softmax 포함\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 정규화 (weight_decay)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKQG3YEW-eq_"
   },
   "source": [
    "# To Do list!\n",
    "1. SimpleNN 모델의 정의\n",
    " - [128, 64, 10] fully connected layer를 구성한다.\n",
    " - 각 fclayer는 relu activation을 쓴다.\n",
    "\n",
    " - optimizer 는 adam 으로 학습률 0.001로 한다.\n",
    " - 배치사이즈는 128, 총 epoch는 10으로 한다.\n",
    " - Xavier 초기화로 가중치를 초기화 한다.\n",
    " - 레이어 중간마다 batch normalization을 진행한다.\n",
    " - 첫번째와 두번째 layer는 드롭아웃(0.5)를 추가한다.\n",
    " - l2정규화를 0.01로 설정한다.\n",
    "\n",
    "2. 학습수행 (train acc, loss 확인)\n",
    "3. test acc, loss 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1728980709030,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "7lI8EhTAU_RU"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1728980851490,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "FKb1rmnY6viU"
   },
   "outputs": [],
   "source": [
    "# 모델 정의 (SimpleNN)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        # 첫 번째 레이어 (128 units) + BatchNorm + Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        # 두 번째 레이어 (64 units) + BatchNorm + Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # 네 번째 레이어 (출력층 10 units)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 28x28 이미지를 1D 벡터로 변환\n",
    "\n",
    "        # 첫 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # 두 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # 세 번째 레이어: 출력층\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 가중치 초기화 함수 (Xavier 초기화)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1728980885384,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Volws7ulOmMg",
    "outputId": "876f65f5-dcd0-4458-b034-438e877ed7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]         100,480\n",
      "       BatchNorm1d-2                  [-1, 128]             256\n",
      "           Dropout-3                  [-1, 128]               0\n",
      "            Linear-4                   [-1, 64]           8,256\n",
      "       BatchNorm1d-5                   [-1, 64]             128\n",
      "           Dropout-6                   [-1, 64]               0\n",
      "            Linear-7                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 109,770\n",
      "Trainable params: 109,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화 및 가중치 초기화 적용\n",
    "from torchsummary import summary\n",
    "model = SimpleNN().to(device)\n",
    "model.apply(init_weights)\n",
    "summary(model, (1, 28 * 28), device=str(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1728980928415,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "27uC4xFUOtpr"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 정의 (Adam, L2 정규화 포함)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # L2 정규화 (weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72717,
     "status": "ok",
     "timestamp": 1728981019734,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "fUOVw1N9O31I",
    "outputId": "0f8fd2cb-9112-4439-ff60-9a30ae42d683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7873\n",
      "Epoch [2/10], Loss: 0.4503\n",
      "Epoch [3/10], Loss: 0.4058\n",
      "Epoch [4/10], Loss: 0.3859\n",
      "Epoch [5/10], Loss: 0.3754\n",
      "Epoch [6/10], Loss: 0.3661\n",
      "Epoch [7/10], Loss: 0.3663\n",
      "Epoch [8/10], Loss: 0.3682\n",
      "Epoch [9/10], Loss: 0.3641\n",
      "Epoch [10/10], Loss: 0.3642\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 1. 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. 모델에 입력 데이터를 전달하고 손실 계산\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # 3. 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9500,
     "status": "ok",
     "timestamp": 1728981048391,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "kXDrmv2YTvZL",
    "outputId": "8879ddb1-92dc-4f46-d220-9f4f61ddaedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1742, Accuracy: 96.18/10000 (96.18%)\n"
     ]
    }
   ],
   "source": [
    "test_loss_list, acc_list=test_model(model, test_loader, criterion, device)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMicxp/En+WUpSR6yj3PETQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
