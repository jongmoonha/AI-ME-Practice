{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKrMEYPecVdY"
   },
   "source": [
    "# Chapter 3. Deep learning Practice\n",
    "##  \"Pytorch\" 라이브러리를 활용한 Basic Deep Neural Network 프로그래밍\n",
    "## 프로그래밍 구조\n",
    "0. 데이터 로드 및 전처리\n",
    "1. 모델정의\n",
    "2. 모델하이퍼 파라미터 설정\n",
    "3. 모델 학습\n",
    "4. 결과예측\n",
    "\n",
    "\n",
    "조건:\n",
    "- input 데이터: MNIST (0~9 숫자 이미지. -> [28x28] 크기 이미지를 [1x784] numeric data라고 생각한다.\n",
    "- objective: MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOAMr_VkffXl"
   },
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10716,
     "status": "ok",
     "timestamp": 1728980677692,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Xyas0IBMcINZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9055,
     "status": "ok",
     "timestamp": 1728980688075,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "eMCRu2JEgcNb",
    "outputId": "31a56809-a228-4353-cddc-7980a4686a04"
   },
   "outputs": [],
   "source": [
    "# 0. 데이터 로드 & 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "'''\n",
    "ToTensor()의 기능\n",
    "이미지를 PIL 이미지 또는 numpy 배열의 구조를 \"Channel x Height x Width\"로 바꾸고,\n",
    "이미지 픽셀값 [0~225]를 [0~1]로 수정.\n",
    "'''\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1728980702347,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "x3cNEj8CyaKE"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1728978953925,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "4eBhWoN0hUGo"
   },
   "outputs": [],
   "source": [
    "# 1. 모델 정의\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 16)  # 첫 번째 레이어\n",
    "        self.fc2 = nn.Linear(16, 10)        # 세 번째 레이어 (출력층)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 입력 이미지를 1D 벡터로 변환\n",
    "        x = torch.relu(self.fc1(x)) # 첫 번째 레이어: ReLU\n",
    "        x = self.fc2(x) # 출력층: Softmax는 CrossEntropyLoss에 내장되어 있으므로 사용하지 않음\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1728979029920,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "H-h9fQygfbzc",
    "outputId": "4abf5322-d73e-49a2-f0f1-b518fa982f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 16]          12,560\n",
      "            Linear-2                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 12,730\n",
      "Trainable params: 12,730\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = SimpleNN().to(device)\n",
    "summary(model, (1, 28 * 28), device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1728979427732,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "-X22U1ewiswM"
   },
   "outputs": [],
   "source": [
    "# 2. 모델 하이퍼 파라미터 설정 - 손실 함수 및 옵티마이저 정의 (cross entropy, Adam 사용)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40241,
     "status": "ok",
     "timestamp": 1728979468581,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "B4uFEwybhWif",
    "outputId": "1930bab8-9dfd-44c3-89d3-7bf2ad119b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24680571258068085\n",
      "Epoch 2, Loss: 0.3889806866645813\n",
      "Epoch 3, Loss: 0.6511635780334473\n",
      "Epoch 4, Loss: 0.3797954022884369\n",
      "Epoch 5, Loss: 0.2404673993587494\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "for epoch in range(5):  # 5 epoch 학습\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device) # 데이터를 device로 이동\n",
    "        optimizer.zero_grad() # 옵티마이저 초기화\n",
    "        output = model(data) # 모델에 입력 데이터를 전달\n",
    "        loss = criterion(output, target) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 모델 파라미터(업데이트)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1728981030727,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "hWwVixVVgfSM"
   },
   "outputs": [],
   "source": [
    "# 4. 결과예측\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (Dropout이나 BatchNorm 비활성화)\n",
    "\n",
    "    test_loss_list = []\n",
    "    acc_list = []\n",
    "    with torch.no_grad():  # 테스트 시에는 기울기를 계산하지 않으므로 메모리 최적화\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)# 데이터를 모델과 동일한 디바이스로 이동\n",
    "            output = model(data)# 모델에 입력 데이터 전달\n",
    "            # 손실 계산\n",
    "            test_loss_list.append(criterion(output, target).item())\n",
    "            # 예측 결과와 실제 정답 비교\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 가장 높은 값의 인덱스를 예측으로 사용\n",
    "            acc_list.append(pred.eq(target.view_as(pred)).sum().item())\n",
    "    # 평균 손실 및 정확도 출력\n",
    "    test_loss = sum(test_loss_list) / len(test_loader.dataset)\n",
    "    accuracy = 100. * sum(acc_list)  / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "    return test_loss_list, acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7114,
     "status": "ok",
     "timestamp": 1728979613526,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Loo7Ve4O23w0",
    "outputId": "18f23b78-5212-48eb-fa14-fc4f09e2635d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1934, Accuracy: 94.56/10000 (94.56%)\n"
     ]
    }
   ],
   "source": [
    "test_loss_list, acc_list=test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDoqeqeb6etY"
   },
   "source": [
    "# Pytorch tuning list\n",
    "1. Activation layers\n",
    "  - torch.relu, torch.sigmoid, torch.tanh, torch.PReLU, 등 지원\n",
    "\n",
    "2. Optimizaer\n",
    "  - optim.Adam 외에도 (optim.Adadelta, optim.AdamW, optim.SGD, optim.RMSprop 등 지원함)  \n",
    "  (ex)\n",
    "  ```\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "  ```\n",
    "\n",
    "3. Mini-batch Training\n",
    "  - DataLoader에서 배치 크기를 조정\n",
    "\n",
    "4. Weight initialization\n",
    "  - torch.nn.init을 사용해서 초기화 사용자 함수(init_weights) 작성\n",
    "  - model.apply(init_weights)로 적용\n",
    "  - default: He Normal (from torch 2.1)\n",
    "  (ex)\n",
    "  ```\n",
    "  def init_weights(m):\n",
    "      if isinstance(m, nn.Linear):\n",
    "          nn.init.xavier_uniform_(m.weight)  # Xavier 초기화 적용\n",
    "          nn.init.constant_(m.bias, 0)       # 바이어스는 0으로 초기화\n",
    "  model = SimpleNN()\n",
    "  model.apply(init_weights)        \n",
    "  ```\n",
    "  \n",
    "5. Batch Normalization\n",
    "  - 각 레이어 사이에 nn.BatchNorm1d 입력해서 배치 정규화 추가\n",
    "  (ex)  \n",
    "  ```\n",
    "  self.bn2 = nn.BatchNorm1d(64)\n",
    "  ```\n",
    "\n",
    "6. Regularization\n",
    "  - L2 - reg: lambda = optimizer에서 weight_decay값 조절\n",
    "  - Dropout: nn.Dropout(비율) 로 조절(ex. nn.Dropout(0.5))\n",
    "\n",
    "### [튜닝 적용 예시]\n",
    "\n",
    "\n",
    "```\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 첫 번째 레이어 (28*28 input -> 128 hidden units)\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128) # Batch Normalization\n",
    "        self.dropout1 = nn.Dropout(0.5)  # 드롭아웃 추가 (50%)\n",
    "        \n",
    "        # 두 번째 레이어 (128 hidden units -> 64 hidden units)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64) # Batch Normalization\n",
    "        self.dropout2 = nn.Dropout(0.5)  # 드롭아웃 추가 (50%)\n",
    "        \n",
    "        # 세 번째 레이어 (64 hidden units -> 10 output units)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 레이어: ReLU활성화 + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # 두 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "model.apply(init_weights)  # 가중치 초기화 적용\n",
    "\n",
    "## 손실 함수 및 옵티마이저 정의 (Adam 사용, L2 정규화 적용)\n",
    "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss는 Softmax 포함\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 정규화 (weight_decay)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKQG3YEW-eq_"
   },
   "source": [
    "# To Do list!\n",
    "1. SimpleNN 모델의 정의\n",
    " - [128, 64, 10] fully connected layer를 구성한다.\n",
    " - 각 fclayer는 relu activation을 쓴다.\n",
    "\n",
    " - optimizer 는 adam 으로 학습률 0.001로 한다.\n",
    " - 배치사이즈는 128, 총 epoch는 10으로 한다.\n",
    " - Xavier 초기화로 가중치를 초기화 한다.\n",
    " - 레이어 중간마다 batch normalization을 진행한다.\n",
    " - 첫번째와 두번째 layer는 드롭아웃(0.5)를 추가한다.\n",
    " - l2정규화를 0.01로 설정한다.\n",
    "\n",
    "2. 학습수행 (train acc, loss 확인)\n",
    "3. test acc, loss 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1728980709030,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "7lI8EhTAU_RU"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1728980851490,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "FKb1rmnY6viU"
   },
   "outputs": [],
   "source": [
    "# 모델 정의 (SimpleNN)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        # 첫 번째 레이어 (128 units) + BatchNorm + Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        # 두 번째 레이어 (64 units) + BatchNorm + Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # 네 번째 레이어 (출력층 10 units)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 28x28 이미지를 1D 벡터로 변환\n",
    "\n",
    "        # 첫 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # 두 번째 레이어: ReLU + BatchNorm + Dropout\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # 세 번째 레이어: 출력층\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 가중치 초기화 함수 (Xavier 초기화)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1728980885384,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "Volws7ulOmMg",
    "outputId": "876f65f5-dcd0-4458-b034-438e877ed7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]         100,480\n",
      "       BatchNorm1d-2                  [-1, 128]             256\n",
      "           Dropout-3                  [-1, 128]               0\n",
      "            Linear-4                   [-1, 64]           8,256\n",
      "       BatchNorm1d-5                   [-1, 64]             128\n",
      "           Dropout-6                   [-1, 64]               0\n",
      "            Linear-7                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 109,770\n",
      "Trainable params: 109,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화 및 가중치 초기화 적용\n",
    "from torchsummary import summary\n",
    "model = SimpleNN().to(device)\n",
    "model.apply(init_weights)\n",
    "summary(model, (1, 28 * 28), device=str(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1728980928415,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "27uC4xFUOtpr"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 정의 (Adam, L2 정규화 포함)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # L2 정규화 (weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72717,
     "status": "ok",
     "timestamp": 1728981019734,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "fUOVw1N9O31I",
    "outputId": "0f8fd2cb-9112-4439-ff60-9a30ae42d683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7873\n",
      "Epoch [2/10], Loss: 0.4503\n",
      "Epoch [3/10], Loss: 0.4058\n",
      "Epoch [4/10], Loss: 0.3859\n",
      "Epoch [5/10], Loss: 0.3754\n",
      "Epoch [6/10], Loss: 0.3661\n",
      "Epoch [7/10], Loss: 0.3663\n",
      "Epoch [8/10], Loss: 0.3682\n",
      "Epoch [9/10], Loss: 0.3641\n",
      "Epoch [10/10], Loss: 0.3642\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 1. 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. 모델에 입력 데이터를 전달하고 손실 계산\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # 3. 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9500,
     "status": "ok",
     "timestamp": 1728981048391,
     "user": {
      "displayName": "Park Chan Hee",
      "userId": "12253724632409422807"
     },
     "user_tz": -540
    },
    "id": "kXDrmv2YTvZL",
    "outputId": "8879ddb1-92dc-4f46-d220-9f4f61ddaedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1742, Accuracy: 96.18/10000 (96.18%)\n"
     ]
    }
   ],
   "source": [
    "test_loss_list, acc_list=test_model(model, test_loader, criterion, device)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMicxp/En+WUpSR6yj3PETQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
